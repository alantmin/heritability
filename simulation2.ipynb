{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import copy\n",
    "import pandas as pd\n",
    "import matplotlib.ticker as ticker\n",
    "import pickle\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to do heritability estimation\n",
    "class heritability :\n",
    "    def __init__(self, maf, n_indiv, n_marker, hsq) :\n",
    "        self.maf = maf\n",
    "        self.n_indiv = n_indiv\n",
    "        self.n_marker = n_marker\n",
    "        self.hsq = hsq\n",
    "        self.genotypes = self.get_genotypes()\n",
    "        self.genotypes_norm = self.normalize_genotypes()\n",
    "        self.grm = self.get_grm()\n",
    "        self.noncausal_linked_set = False\n",
    "    \n",
    "    # Returns the genotypes for this class. Each row is an individual\n",
    "    # And each column is a marker. I.e. there are n_indiv rows and n_marker columns\n",
    "    def get_genotypes(self) :\n",
    "        if len(self.maf) > 1 and len(self.maf) != self.n_marker :\n",
    "            raise Exception(\"Heritability class (get_genotypes): len(self.maf) != self.n_marker\")\n",
    "        return np.random.binomial(2, self.maf, size = (self.n_indiv, self.n_marker))\n",
    "\n",
    "    # Normalizes the genotypes according to (x-2p)/sqrt(2p(1-p))\n",
    "    def normalize_genotypes(self) :\n",
    "        genotypes = self.genotypes\n",
    "        genotypes_norm = np.zeros(self.genotypes.shape)\n",
    "        for i in range(genotypes.shape[1]) :\n",
    "            p = np.sum(genotypes[:,i])/(genotypes.shape[0] * 2)\n",
    "            genotypes_norm[:,i] = (genotypes[:,i] - 2*p)/np.sqrt(2 * p * (1-p))\n",
    "        return genotypes_norm\n",
    "    \n",
    "    # Calculates the GRM according to XX^T \n",
    "    def get_grm(self) :\n",
    "        return self.genotypes_norm @ self.genotypes_norm.transpose() / self.n_marker\n",
    "    \n",
    "    # Calculates the GRM but only uses the first num_marker markers\n",
    "    def set_sub_grm(self, num_marker) :\n",
    "        tmp = self.genotypes_norm[:,0:num_marker]\n",
    "        self.grm = tmp @ tmp.transpose() / num_marker\n",
    "    \n",
    "    # This calculates genotypes based off of ALL genotypes in self.genotypes_norm\n",
    "    # This means that if you call duplicate_genotypes or noncausal_genotypes, and then later\n",
    "    # Call get_phenotypes, it will use all of the duplicates/noncausals\n",
    "    def get_phenotypes(self) :\n",
    "        n_causal = int(self.n_marker)\n",
    "        betas = np.random.normal(0, np.sqrt(self.hsq/n_causal), n_causal)\n",
    "        phen = self.genotypes_norm.dot(betas) + np.random.normal(0, np.sqrt(1-self.hsq), self.n_indiv)\n",
    "        return phen\n",
    "     \n",
    "    # Replaces each genotype of genotypes with a probability replace_prob\n",
    "    # Goes through each row and rolls a bernoulli for each marker\n",
    "    def replace_with_duplicates(self, genotypes, replace_prob) :\n",
    "        # Go through every marker\n",
    "        for i in range(genotypes.shape[0]):\n",
    "            for j in range(genotypes.shape[1]) :\n",
    "                # Check if we should replace this marker\n",
    "                if np.random.uniform() < replace_prob :\n",
    "                    genotypes[i, j] = np.random.binomial(2, self.maf)\n",
    "    \n",
    "    # m_dup is the number of markers that are being duplicated. Always duplicates the first m_dup\n",
    "    # n_dup is the number of times that those m_dup markers are duplicated\n",
    "    # Also updates GRM \n",
    "    def set_duplicate_genotypes(self, m_dup, n_dup, replace_prob = 0) :\n",
    "        dup_genotypes = self.genotypes[:,0:m_dup]\n",
    "        rep_genotypes = np.repeat(dup_genotypes, n_dup, 1)\n",
    "        self.replace_with_duplicates(rep_genotypes, replace_prob)\n",
    "        new_genotypes = np.append(self.genotypes, rep_genotypes , 1)\n",
    "        self.genotypes = new_genotypes\n",
    "        self.genotypes_norm = self.normalize_genotypes()\n",
    "        self.n_marker = self.genotypes.shape[1]\n",
    "        self.grm = self.get_grm()\n",
    "        \n",
    "    # This adds new noncausal markers to the dataset. Adds num_noncausal markers to each indiv\n",
    "    # These are unlinked\n",
    "    def add_noncausal_genotypes(self, num_noncausal) :\n",
    "        noncausal_add = np.random.binomial(2, self.maf, size = (self.n_indiv, num_noncausal))\n",
    "        new_genotypes = np.append(self.genotypes, noncausal_add, 1)\n",
    "        self.genotypes = new_genotypes\n",
    "        self.genotypes_norm = self.normalize_genotypes()\n",
    "        self.grm = self.get_grm()\n",
    "        self.n_marker = self.genotypes.shape[1]\n",
    "    \n",
    "    # Adds new markers. The first time you call this function, it will add num_markers noncausal markers\n",
    "    # To the genotypes and recalculate the grm. \n",
    "    # Consecutive calls will copy the last num_markers and append them to the end of genotypes\n",
    "    def add_noncausal_linked_genotypes(self, num_markers) :\n",
    "        if self.noncausal_linked_set == False :\n",
    "            self.add_noncausal_genotypes(num_markers)\n",
    "            self.noncausal_linked_set = True\n",
    "        else :\n",
    "            # This bottom line of code is a little weird but the first colon means we take all rows\n",
    "            # The second -num_markers: means we take the last num_markers columns\n",
    "            dup_genotypes = self.genotypes[:,-num_markers:]\n",
    "            new_genotypes = np.append(self.genotypes, np.repeat(dup_genotypes, 1, 1), 1)\n",
    "            self.genotypes = new_genotypes\n",
    "            self.genotypes_norm = self.normalize_genotypes()\n",
    "            self.grm = self.get_grm()\n",
    "            self.n_marker = self.genotypes.shape[1]\n",
    "        \n",
    "    \n",
    "# Likelihood for sigma = [sigma_g^2, sigma_e^2]\n",
    "def ll(sigma, grm, phenotypes) :\n",
    "    sigma_g = sigma[0]\n",
    "    sigma_e = sigma[1]\n",
    "    n_indiv = grm.shape[0]\n",
    "    V = sigma_g * grm + sigma_e * np.identity(n_indiv)\n",
    "    s, logdet = np.linalg.slogdet(V)\n",
    "    return -n_indiv/2 * np.log(2 * np.pi) - 1/2 * (s * logdet + phenotypes.transpose() @ np.linalg.inv(V) @ phenotypes)\n",
    "    \n",
    "\n",
    "    \n",
    "maf = .2\n",
    "n_indiv = 1000\n",
    "n_marker = 200\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing the number of individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afr_maf = pd.read_csv(\"markers1shuffle.txt\", delimiter = \" \")[\"afr_alt\"].to_numpy()\n",
    "\n",
    "# Use the same phenotypes and genotypes, but continue to duplicate the genotypes\n",
    "# Here we are duplicating the first 40 genotypes up to 8 times. The duplicated genotypes are causal.\n",
    "f, axs = plt.subplots(4, 2)\n",
    "f.set_size_inches(16, 8)\n",
    "f.subplots_adjust(hspace = .4, wspace = .2)\n",
    "axs = axs.ravel()\n",
    "xs = []\n",
    "ys = []\n",
    "zs = []\n",
    "i = 1\n",
    "n_iter = 10\n",
    "index = 0\n",
    "x,y = np.meshgrid(np.arange(.01, 1, step = .3), np.arange(0.01, 1, step = .1))\n",
    "for n_people, n_markers in [[1000, 200], [200, 1000], [200, 3000], [2000, 1000]]:\n",
    "    print(n_people, n_markers)\n",
    "    for repeats in [0, int(n_markers * .1)]:\n",
    "        z_iter = []\n",
    "        for it in range(n_iter) :\n",
    "            z = np.zeros(x.shape)\n",
    "            h = heritability(afr_maf[:n_markers], n_people, n_markers, .8)\n",
    "            phenotypes = h.get_phenotypes()\n",
    "            if repeats != 0:\n",
    "                h.set_duplicate_genotypes(repeats, 8)\n",
    "            x,y = np.meshgrid(np.arange(.01, 1, step = .3), np.arange(0.01, 1, step = .1))\n",
    "            for i in range(x.shape[0]) :\n",
    "                for j in range(x.shape[1]) :\n",
    "                    l = ll([x[i,j],y[i,j]], h.grm, phenotypes)\n",
    "                    if l < -120 :\n",
    "                        z[i,j] = l#-120\n",
    "                    else :\n",
    "                        z[i,j] = l\n",
    "            z_iter.append(z)\n",
    "        z = sum(z_iter)/n_iter\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        zs.append(z)\n",
    "        cf = axs[index].contourf(x,y,z)\n",
    "        f.colorbar(cf, ax = axs[index])\n",
    "        axs[index].set_xlabel(\"Sigma_g\")\n",
    "        axs[index].set_ylabel(\"Sigma_e\")\n",
    "        axs[index].set_title(f\"{n_people} Repeats\")\n",
    "        index += 1\n",
    "f.suptitle(\"Duplicated (40) Causal Genotypes\", size = 20, y = .95)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xs, open(\"x.pickle\", \"wb\"))\n",
    "pickle.dump(ys, open(\"y.pickle\", \"wb\"))\n",
    "pickle.dump(zs, open(\"z.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thing to format colorbar\n",
    "def myfmt(x, pos):\n",
    "    return '{0:.3f}'.format(x)\n",
    "\n",
    "cmap = mpl.cm.cool\n",
    "norm = mpl.colors.Normalize(vmin=-.2, vmax=0)\n",
    "\n",
    "zs = pickle.load(open(\"z.pickle\", \"rb\"))\n",
    "xs = pickle.load(open(\"x.pickle\", \"rb\"))\n",
    "ys = pickle.load(open(\"y.pickle\", \"rb\"))\n",
    "f, axs = plt.subplots(5,2, figsize=[10,12])\n",
    "# f.set_size(12, 12)\n",
    "f.subplots_adjust(hspace = .4, wspace = .2)\n",
    "axs = axs.ravel()\n",
    "titles = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]\n",
    "index = 0 \n",
    "n1000q = np.quantile(zs[1]/1000 - max(zs[1].flatten())/1000, .6)\n",
    "n200q = np.quantile(zs[2]/200 - max(zs[2].flatten())/200, .6)\n",
    "for n_people, n_markers in [[1000, 200], [200, 1000], [200, 3000], [2000, 1000]]:\n",
    "    for repeats in [0, int(n_markers * .1)]:\n",
    "        znew = copy.deepcopy(zs[index])\n",
    "        znew = znew/(n_people)\n",
    "        znew = znew - max(znew.flatten())\n",
    "        if n_people >= 1000:\n",
    "            znew[znew < n1000q] = n1000q\n",
    "            cf = axs[index].contourf(xs[index], ys[index], znew,  levels=np.linspace(-.2, 0, 41))\n",
    "        else:\n",
    "            znew[znew < n200q] = n200q\n",
    "            cf = axs[index].contourf(xs[index], ys[index], znew,  levels=np.linspace(-0.036, 0, 41))\n",
    "        max_x = xs[1][znew == znew.max()]\n",
    "        max_y = ys[1][znew == znew.max()]\n",
    "        axs[index].scatter(max_x, max_y, c=\"red\")\n",
    "        if index in [1, 3, 5, 7]:\n",
    "            axs[index].get_yaxis().set_visible(False)\n",
    "        if index in [0, 1, 2, 3, 4, 5]:\n",
    "            axs[index].get_xaxis().set_visible(False)\n",
    "        if index == 0 :\n",
    "            axs[index].set_ylabel(\"(i)\")\n",
    "        if index == 2 :\n",
    "            axs[index].set_ylabel(\"(ii)\")\n",
    "        if index == 4 :\n",
    "            axs[index].set_ylabel(\"(iii)\")\n",
    "        if index == 6 :\n",
    "            axs[index].set_ylabel(\"(iv)\")\n",
    "        if index == 0 :\n",
    "            axs[index].set_title(\"A\")\n",
    "        if index == 1:\n",
    "            axs[index].set_title(\"B\")\n",
    "        index += 1 \n",
    "\n",
    "cf = axs[index].contourf(xs[0], ys[0], znew,  levels=np.linspace(-.2, 0, 41))\n",
    "axs[index].set_visible(False)\n",
    "f.colorbar(cf, ax=axs[index], format=ticker.FuncFormatter(myfmt), location=\"top\")\n",
    "index += 1\n",
    "cf = axs[index].contourf(xs[0], ys[0], znew,  levels=np.linspace(-.036, 0, 41))\n",
    "axs[index].set_visible(False)\n",
    "f.colorbar(cf, ax=axs[index], format=ticker.FuncFormatter(myfmt), location=\"top\")\n",
    "f.supxlabel(r'$\\sigma_g^2$')\n",
    "f.supylabel(r'$\\sigma_e^2$')\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "f.tight_layout()\n",
    "f.savefig(\"maxlike_repeat_params.png\", dpi=300, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
